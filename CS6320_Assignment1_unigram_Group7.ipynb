{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Unigram Model**"
      ],
      "metadata": {
        "id": "U55d-9swsfoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------\n",
        "# CS6320 - NLP - Assignment 1 - Unigram Model\n",
        "# -------------------------------------\n",
        "\n",
        "print(\"\\n-------------------------\\nGroup 7 - NLP Assignment 1\")\n",
        "print(\"Bhanu Maneesh Reddy Mannem (BXM220055)\")\n",
        "print(\"Snehal Kumar Ketala (SXK220463)\")\n",
        "print(\"Lalithya Mada (LXM230002)\")\n",
        "print(\"-------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJtygHrHsFwq",
        "outputId": "cf7d06a6-4f5c-4088-ca6e-c825d2cd9b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------------\n",
            "Group 7 - NLP Assignment 1\n",
            "Bhanu Maneesh Reddy Mannem (BXM220055)\n",
            "Snehal Kumar Ketala (SXK220463)\n",
            "Lalithya Mada (LXM230002)\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries and Define Utility Functions**"
      ],
      "metadata": {
        "id": "jMyirVDGhs8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "from collections import Counter, defaultdict\n",
        "import requests\n",
        "\n",
        "# Global dictionary to store final results for output display\n",
        "output_data = {}\n",
        "\n",
        "# Function to compute perplexity\n",
        "def compute_perplexity(probabilities, tokens, log_probs):\n",
        "    print(\"\\n--- Calculating Perplexity ---\")\n",
        "    token_count = defaultdict(int)\n",
        "    total_tokens = 0\n",
        "    for token in tokens:\n",
        "        token_count[token] += 1\n",
        "        total_tokens += 1\n",
        "\n",
        "    total_log_prob = 0\n",
        "    for token in token_count:\n",
        "        if token in log_probs:\n",
        "            log_prob = log_probs[token]\n",
        "        else:\n",
        "            log_prob = log_probs['UNK']\n",
        "        total_log_prob += (-1) * log_prob * token_count[token]\n",
        "\n",
        "    perplexity_value = math.exp(total_log_prob / total_tokens)\n",
        "    print(f\"Perplexity Calculated: {perplexity_value}\")\n",
        "    return perplexity_value\n",
        "\n",
        "# Function to calculate unigram probabilities with Add-k Smoothing\n",
        "def unigram_add_k_smoothing(train_words, smoothing_factor):\n",
        "    print(f\"\\n--- Applying Add-k Smoothing (k={smoothing_factor}) ---\")\n",
        "    word_counts, total_word_count = defaultdict(int), 0\n",
        "    for word in train_words:\n",
        "        word_counts[word] += 1\n",
        "        total_word_count += 1\n",
        "\n",
        "    smoothed_probs = {}\n",
        "    for word, count in word_counts.items():\n",
        "        smoothed_probs[word] = (count + smoothing_factor) / (total_word_count + smoothing_factor * (len(word_counts) + 1))  # +1 for UNK token\n",
        "\n",
        "    # Assign probability to UNK token\n",
        "    smoothed_probs['UNK'] = smoothing_factor / (total_word_count + smoothing_factor * (len(word_counts) + 1))\n",
        "\n",
        "    print(f\"Add-k Smoothing Applied (k={smoothing_factor})\")\n",
        "    return smoothed_probs, word_counts, total_word_count\n",
        "\n",
        "# Laplace Smoothing (k=1)\n",
        "def laplace_smoothing(train_words):\n",
        "    print(\"\\n--- Applying Laplace Smoothing (k=1) ---\")\n",
        "    return unigram_add_k_smoothing(train_words, 1)\n",
        "\n",
        "print(\"Libraries imported and utility functions defined.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6L6oVRhsnkK",
        "outputId": "ca99b542-d9aa-4393-fa0b-5e89c9c7c862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported and utility functions defined.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read and Preprocess Data (Including UNK Token for Rare Words)**"
      ],
      "metadata": {
        "id": "taXrGvxFh1uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated to load data from URL\n",
        "def load_and_preprocess(url, threshold=1):\n",
        "    print(f\"--- Loading and Preprocessing Data from {url} ---\")\n",
        "\n",
        "    # Fetch the data from the URL\n",
        "    response = requests.get(url)\n",
        "    data = response.text\n",
        "\n",
        "    # Preprocess data (lowercase, remove special characters)\n",
        "    data_clean = re.sub(r'\\W', ' ', data.lower()).split()\n",
        "\n",
        "    # Replace rare words with UNK\n",
        "    word_frequencies = Counter(data_clean)\n",
        "    processed_data = [\n",
        "        word if word_frequencies[word] > threshold else 'UNK' for word in data_clean\n",
        "    ]\n",
        "\n",
        "    print(f\"Data Loaded and Preprocessed from {url}\")\n",
        "    return processed_data\n",
        "\n",
        "train_url = \"https://raw.githubusercontent.com/maneeshmbr/unigram-and-bigram-models---NLP/master/A1_DATASET/A1_DATASET/train.txt\"\n",
        "validation_url = \"https://raw.githubusercontent.com/maneeshmbr/unigram-and-bigram-models---NLP/master/A1_DATASET/A1_DATASET/val.txt\"\n",
        "\n",
        "train_words = load_and_preprocess(train_url, threshold=1)  # Treat words appearing only once as UNK\n",
        "validation_words = load_and_preprocess(validation_url)\n",
        "\n",
        "print(f\"Sample tokens from training data: {train_words[:10]}\")\n",
        "print(f\"Sample tokens from validation data: {validation_words[:10]}\")\n",
        "\n",
        "print(f\"Total words in training set: {len(train_words)}\")\n",
        "print(f\"Total unique words in training set (with UNK): {len(set(train_words))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNpeUAn4sno-",
        "outputId": "3986237d-82f7-402d-9933-6390a4b9b5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading and Preprocessing Data from https://raw.githubusercontent.com/maneeshmbr/unigram-and-bigram-models---NLP/master/A1_DATASET/A1_DATASET/train.txt ---\n",
            "Data Loaded and Preprocessed from https://raw.githubusercontent.com/maneeshmbr/unigram-and-bigram-models---NLP/master/A1_DATASET/A1_DATASET/train.txt\n",
            "--- Loading and Preprocessing Data from https://raw.githubusercontent.com/maneeshmbr/unigram-and-bigram-models---NLP/master/A1_DATASET/A1_DATASET/val.txt ---\n",
            "Data Loaded and Preprocessed from https://raw.githubusercontent.com/maneeshmbr/unigram-and-bigram-models---NLP/master/A1_DATASET/A1_DATASET/val.txt\n",
            "Sample tokens from training data: ['i', 'booked', 'two', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the']\n",
            "Sample tokens from validation data: ['i', 'stayed', 'for', 'four', 'nights', 'while', 'attending', 'a', 'conference', 'the']\n",
            "Total words in training set: 80300\n",
            "Total unique words in training set (with UNK): 3099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate Unsmoothed Unigram Probabilities**"
      ],
      "metadata": {
        "id": "5ZUS6WVpiCbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_unigram_probabilities(words):\n",
        "    print(\"\\n--- Calculating Unsmoothed Unigram Probabilities ---\")\n",
        "    word_frequencies = Counter(words)\n",
        "    total_words = len(words)\n",
        "\n",
        "    unigram_probs = {word: freq / total_words for word, freq in word_frequencies.items()}\n",
        "    unigram_log_probs = {word: math.log(prob) for word, prob in unigram_probs.items()}\n",
        "\n",
        "    print(f\"Unsmoothed Unigram Probabilities Calculated\")\n",
        "    return unigram_probs, unigram_log_probs, word_frequencies\n",
        "\n",
        "# Calculate probabilities and log probabilities\n",
        "unigram_probs, unigram_log_probs, word_frequencies = compute_unigram_probabilities(train_words)\n",
        "\n",
        "print(\"\\n--- Unsmoothed Unigram Probabilities (Top 10) ---\")\n",
        "for word, prob in list(unigram_probs.items())[:10]:\n",
        "    print(f\"{word}: {prob:.6f}\")\n",
        "\n",
        "# Add UNK probability if not in the vocabulary\n",
        "unigram_probs['UNK'] = 1 / len(train_words)\n",
        "unigram_log_probs['UNK'] = math.log(unigram_probs['UNK'])\n",
        "\n",
        "# Calculate perplexity for training data (without smoothing)\n",
        "unsmoothed_perplexity = compute_perplexity(unigram_probs, train_words, unigram_log_probs)\n",
        "output_data['Perplexity (Unsmoothed)'] = unsmoothed_perplexity\n",
        "print(f\"Perplexity (Unsmoothed): {unsmoothed_perplexity}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1DMwZbFsntm",
        "outputId": "faa89833-d206-4536-e243-58b047f213a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating Unsmoothed Unigram Probabilities ---\n",
            "Unsmoothed Unigram Probabilities Calculated\n",
            "\n",
            "--- Unsmoothed Unigram Probabilities (Top 10) ---\n",
            "i: 0.021445\n",
            "booked: 0.001071\n",
            "two: 0.001606\n",
            "rooms: 0.002528\n",
            "four: 0.000262\n",
            "months: 0.000100\n",
            "in: 0.016413\n",
            "advance: 0.000087\n",
            "at: 0.009278\n",
            "the: 0.066189\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 519.7966347457758\n",
            "Perplexity (Unsmoothed): 519.7966347457758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Apply Add-k and Laplace Smoothing (with UNK Token)**"
      ],
      "metadata": {
        "id": "vMgBaNb4iY4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add-k Smoothing (k=0.5)\n",
        "smoothed_probs_k_0_5, _, _ = unigram_add_k_smoothing(train_words, 0.5)\n",
        "log_probs_k_0_5 = {word: math.log(prob) for word, prob in smoothed_probs_k_0_5.items()}\n",
        "\n",
        "print(\"\\n--- Add-k Smoothing (k=0.5) Unigram Probabilities (Top 10) ---\")\n",
        "for word, prob in list(smoothed_probs_k_0_5.items())[:10]:\n",
        "    print(f\"{word}: {prob:.6f}\")\n",
        "\n",
        "perplexity_k_0_5 = compute_perplexity(smoothed_probs_k_0_5, validation_words, log_probs_k_0_5)\n",
        "output_data['Perplexity (Add-k = 0.5)'] = perplexity_k_0_5\n",
        "print(f\"Perplexity (Add-k = 0.5): {perplexity_k_0_5}\")\n",
        "\n",
        "# Add-k Smoothing (k=3)\n",
        "smoothed_probs_k_3, _, _ = unigram_add_k_smoothing(train_words, 3)\n",
        "log_probs_k_3 = {word: math.log(prob) for word, prob in smoothed_probs_k_3.items()}\n",
        "\n",
        "print(\"\\n--- Add-k Smoothing (k=3) Unigram Probabilities (Top 10) ---\")\n",
        "for word, prob in list(smoothed_probs_k_3.items())[:10]:\n",
        "    print(f\"{word}: {prob:.6f}\")\n",
        "\n",
        "perplexity_k_3 = compute_perplexity(smoothed_probs_k_3, validation_words, log_probs_k_3)\n",
        "output_data['Perplexity (Add-k = 3)'] = perplexity_k_3\n",
        "print(f\"Perplexity (Add-k = 3): {perplexity_k_3}\")\n",
        "\n",
        "# Laplace Smoothing (k=1)\n",
        "laplace_probs, _, _ = laplace_smoothing(train_words)  # This line will now work correctly\n",
        "laplace_log_probs = {word: math.log(prob) for word, prob in laplace_probs.items()}\n",
        "\n",
        "print(\"\\n--- Laplace Smoothing Unigram Probabilities (Top 10) ---\")\n",
        "for word, prob in list(laplace_probs.items())[:10]:\n",
        "    print(f\"{word}: {prob:.6f}\")\n",
        "\n",
        "perplexity_laplace = compute_perplexity(laplace_probs, validation_words, laplace_log_probs)\n",
        "output_data['Perplexity (Laplace Smoothing)'] = perplexity_laplace\n",
        "print(f\"Perplexity (Laplace Smoothing): {perplexity_laplace}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSUDc92Ws3rD",
        "outputId": "477306ac-780a-4dae-8ea4-42a83ef0b105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Applying Add-k Smoothing (k=0.5) ---\n",
            "Add-k Smoothing Applied (k=0.5)\n",
            "\n",
            "--- Add-k Smoothing (k=0.5) Unigram Probabilities (Top 10) ---\n",
            "i: 0.021045\n",
            "booked: 0.001057\n",
            "two: 0.001582\n",
            "rooms: 0.002486\n",
            "four: 0.000263\n",
            "months: 0.000104\n",
            "in: 0.016109\n",
            "advance: 0.000092\n",
            "at: 0.009108\n",
            "the: 0.064942\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 642.9113600288241\n",
            "Perplexity (Add-k = 0.5): 642.9113600288241\n",
            "\n",
            "--- Applying Add-k Smoothing (k=3) ---\n",
            "Add-k Smoothing Applied (k=3)\n",
            "\n",
            "--- Add-k Smoothing (k=3) Unigram Probabilities (Top 10) ---\n",
            "i: 0.019252\n",
            "booked: 0.000993\n",
            "two: 0.001473\n",
            "rooms: 0.002299\n",
            "four: 0.000268\n",
            "months: 0.000123\n",
            "in: 0.014743\n",
            "advance: 0.000112\n",
            "at: 0.008348\n",
            "the: 0.059353\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 551.683586701145\n",
            "Perplexity (Add-k = 3): 551.683586701145\n",
            "\n",
            "--- Applying Laplace Smoothing (k=1) ---\n",
            "\n",
            "--- Applying Add-k Smoothing (k=1) ---\n",
            "Add-k Smoothing Applied (k=1)\n",
            "\n",
            "--- Laplace Smoothing Unigram Probabilities (Top 10) ---\n",
            "i: 0.020659\n",
            "booked: 0.001043\n",
            "two: 0.001559\n",
            "rooms: 0.002446\n",
            "four: 0.000264\n",
            "months: 0.000108\n",
            "in: 0.015815\n",
            "advance: 0.000096\n",
            "at: 0.008945\n",
            "the: 0.063741\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 599.9353232181335\n",
            "Perplexity (Laplace Smoothing): 599.9353232181335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity for Training Data Without Smoothing**"
      ],
      "metadata": {
        "id": "wbbWS9Y_ieA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_train_unsmoothed = compute_perplexity(unigram_probs, train_words, unigram_log_probs)\n",
        "output_data['Perplexity (Training Without Smoothing)'] = perplexity_train_unsmoothed\n",
        "print(f\"Perplexity (Training Data Without Smoothing): {perplexity_train_unsmoothed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXd3zDycs3wm",
        "outputId": "1329837a-f63f-425a-87bf-f5a0d59c10a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 519.7966347457758\n",
            "Perplexity (Training Data Without Smoothing): 519.7966347457758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity with Rare Words as Unknown (with Debugging)**"
      ],
      "metadata": {
        "id": "hTQm6tOmiiQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace rare words with 'UNK' in training and validation data (with higher threshold for rare words)\n",
        "def replace_rare_with_unk(train_words, val_words, threshold=2):\n",
        "    # Calculate frequencies of words in the training data\n",
        "    word_frequencies = Counter(train_words)\n",
        "\n",
        "    # Replace rare words in training data with 'UNK'\n",
        "    processed_train_data = [\n",
        "        word if word_frequencies[word] > threshold else 'UNK' for word in train_words\n",
        "    ]\n",
        "\n",
        "    unk_count_train = processed_train_data.count('UNK')\n",
        "    print(f\"Number of 'UNK' tokens in training data: {unk_count_train}\")\n",
        "\n",
        "    # Replace words in validation data with 'UNK' if they are not seen in training or are rare\n",
        "    processed_val_data = [\n",
        "        word if word in word_frequencies and word_frequencies[word] > threshold else 'UNK' for word in val_words\n",
        "    ]\n",
        "\n",
        "    unk_count_val = processed_val_data.count('UNK')\n",
        "    print(f\"Number of 'UNK' tokens in validation data: {unk_count_val}\")\n",
        "\n",
        "    return processed_train_data, processed_val_data\n",
        "\n",
        "\n",
        "# Apply UNK replacement to both training and validation sets\n",
        "train_words_with_unk, validation_words_with_unk = replace_rare_with_unk(train_words, validation_words)\n",
        "\n",
        "print(f\"Sample of modified training data: {train_words_with_unk[:10]}\")\n",
        "print(f\"Sample of modified validation data: {validation_words_with_unk[:10]}\")\n",
        "\n",
        "# Recalculate perplexity with UNK for all smoothing methods\n",
        "\n",
        "# Add-k Smoothing (k=0.5) with UNK\n",
        "smoothed_probs_k_0_5_unk, _, _ = unigram_add_k_smoothing(train_words_with_unk, 0.5)\n",
        "log_probs_k_0_5_unk = {word: math.log(prob) for word, prob in smoothed_probs_k_0_5_unk.items()}\n",
        "perplexity_k_0_5_unk = compute_perplexity(smoothed_probs_k_0_5_unk, validation_words_with_unk, log_probs_k_0_5_unk)\n",
        "output_data['Perplexity (Add-k = 0.5 with UNK)'] = perplexity_k_0_5_unk\n",
        "print(f\"Perplexity (Add-k = 0.5 with UNK): {perplexity_k_0_5_unk}\")\n",
        "\n",
        "# Add-k Smoothing (k=3) with UNK\n",
        "smoothed_probs_k_3_unk, _, _ = unigram_add_k_smoothing(train_words_with_unk, 3)\n",
        "log_probs_k_3_unk = {word: math.log(prob) for word, prob in smoothed_probs_k_3_unk.items()}\n",
        "perplexity_k_3_unk = compute_perplexity(smoothed_probs_k_3_unk, validation_words_with_unk, log_probs_k_3_unk)\n",
        "output_data['Perplexity (Add-k = 3 with UNK)'] = perplexity_k_3_unk\n",
        "print(f\"Perplexity (Add-k = 3 with UNK): {perplexity_k_3_unk}\")\n",
        "\n",
        "# Laplace Smoothing (k=1) with UNK\n",
        "laplace_probs_unk, _, _ = laplace_smoothing(train_words_with_unk)\n",
        "laplace_log_probs_unk = {word: math.log(prob) for word, prob in laplace_probs_unk.items()}\n",
        "perplexity_laplace_unk = compute_perplexity(laplace_probs_unk, validation_words_with_unk, laplace_log_probs_unk)\n",
        "output_data['Perplexity (Laplace with UNK)'] = perplexity_laplace_unk\n",
        "print(f\"Perplexity (Laplace Smoothing with UNK): {perplexity_laplace_unk}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVSHzev9s33j",
        "outputId": "bb52a44e-e84c-43c9-add9-4aae8fcf904f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 'UNK' tokens in training data: 4562\n",
            "Number of 'UNK' tokens in validation data: 1053\n",
            "Sample of modified training data: ['i', 'booked', 'two', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the']\n",
            "Sample of modified validation data: ['i', 'stayed', 'for', 'four', 'nights', 'while', 'attending', 'a', 'conference', 'the']\n",
            "\n",
            "--- Applying Add-k Smoothing (k=0.5) ---\n",
            "Add-k Smoothing Applied (k=0.5)\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 643.9024222445215\n",
            "Perplexity (Add-k = 0.5 with UNK): 643.9024222445215\n",
            "\n",
            "--- Applying Add-k Smoothing (k=3) ---\n",
            "Add-k Smoothing Applied (k=3)\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 537.1491265731175\n",
            "Perplexity (Add-k = 3 with UNK): 537.1491265731175\n",
            "\n",
            "--- Applying Laplace Smoothing (k=1) ---\n",
            "\n",
            "--- Applying Add-k Smoothing (k=1) ---\n",
            "Add-k Smoothing Applied (k=1)\n",
            "\n",
            "--- Calculating Perplexity ---\n",
            "Perplexity Calculated: 596.5664862749533\n",
            "Perplexity (Laplace Smoothing with UNK): 596.5664862749533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying All Results**"
      ],
      "metadata": {
        "id": "F2vkPGF0ipzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for metric, value in output_data.items():\n",
        "    if \"Training Without Smoothing\" not in metric:\n",
        "        print(f\"{metric}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlfaPgNCs3-4",
        "outputId": "52f05f67-2b86-43db-c3e4-2f5bc5190dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (Unsmoothed): 519.7966347457758\n",
            "Perplexity (Add-k = 0.5): 642.9113600288241\n",
            "Perplexity (Add-k = 3): 551.683586701145\n",
            "Perplexity (Laplace Smoothing): 599.9353232181335\n",
            "Perplexity (Add-k = 0.5 with UNK): 643.9024222445215\n",
            "Perplexity (Add-k = 3 with UNK): 537.1491265731175\n",
            "Perplexity (Laplace with UNK): 596.5664862749533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_eiEvYOhkzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}